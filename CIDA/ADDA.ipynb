{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.18.5\n",
      "pytorch version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from easydict import EasyDict\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "# set experiment configs\n",
    "opt = EasyDict()\n",
    "# choose a dataset from [\"quarter-circle\", \"half-circle\"]\n",
    "opt.data = \"half-circle\"\n",
    "# choose a model from [\"CIDA\", \"PCIDA\", \"ADDA\", \"SO\", \"DANN\", \"CDANN\", \"MDD\", \"CUA\"]\n",
    "opt.model = \"ADDA\"\n",
    "# choose run on which device [\"cuda\", \"cpu\"]\n",
    "opt.device = \"cpu\"\n",
    "\n",
    "# set random seed\n",
    "opt.seed = 2333\n",
    "\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pytorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "with open('/Users/avin/Desktop/Intrusion Detection/train.pk', 'rb') as f:\n",
    "    xx, yy = pickle.load(f)\n",
    "with open('/Users/avin/Desktop/Intrusion Detection/test.pk', 'rb') as f:\n",
    "    xx_test,yy_test = pickle.load(f)\n",
    "X,Y = make_imbalance(xx, yy, sampling_strategy={'normal':1500, 'injection':500, 'impersonation':500, 'flooding':500},random_state=0)\n",
    "X_test, Y_test= make_imbalance(xx_test, yy_test, sampling_strategy={'normal':2700, 'injection':100, 'impersonation':100, 'flooding':100},random_state=0)\n",
    "#xx, yy = make_imbalance(X, Y, sampling_strategy={'normal':3000, 'injection':1000, 'impersonation':1000, 'flooding':1000},random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "binarizer = LabelBinarizer()\n",
    "\n",
    "encoded_y = encoder.fit_transform(Y)\n",
    "encoded_y_test = encoder.fit_transform(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,encoded_y.shape[0]):\n",
    "#    if encoded_y[i]==0:\n",
    "#        encoded_y[i]=1\n",
    "#    if encoded_y[i]==2:\n",
    "#        encoded_y[i]=1\n",
    "#for i in range(0,encoded_y.shape[0]):\n",
    "#    if encoded_y[i]==3:\n",
    "#        encoded_y[i]=0\n",
    "#print(np.count_nonzero(encoded_y == 0))\n",
    "#print(np.count_nonzero(encoded_y == 1))#outlier\n",
    "\n",
    "#for i in range(0,encoded_y_test.shape[0]):\n",
    "#    if encoded_y_test[i]==0:\n",
    "#        encoded_y_test[i]=1\n",
    "#    if encoded_y_test[i]==2:\n",
    "#        encoded_y_test[i]=1\n",
    "#for i in range(0,encoded_y_test.shape[0]):\n",
    "#    if encoded_y_test[i]==3:\n",
    "#        encoded_y_test[i]=0\n",
    "#print(np.count_nonzero(encoded_y_test == 0))\n",
    "#print(np.count_nonzero(encoded_y_test == 1))#outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configs\n",
    "opt.num_epoch = 100\n",
    "opt.batch_size = 10\n",
    "opt.lr = 1e-4\n",
    "opt.lr_T = 1e-4\n",
    "opt.gamma = 100\n",
    "opt.beta1 = 0.9\n",
    "opt.weight_decay = 5e-4\n",
    "opt.wgan = False\n",
    "opt.no_bn = True  # do not use batch normalization # True\n",
    "\n",
    "# model size configs\n",
    "opt.nx = 90  # dimension of the input data\n",
    "opt.nh = 800  # dimension of hidden\n",
    "opt.nc = 4  # number of label class\n",
    "\n",
    "# dataset configs\n",
    "\n",
    "opt.dim_domain = 1  # dimension of domain index\n",
    "\n",
    "# number of domains in the dataset\n",
    "if opt.data == \"quarter-circle\":\n",
    "    opt.num_domain = 15\n",
    "    opt.num_source = 6\n",
    "    opt.normalize_domain = False\n",
    "elif opt.data == \"half-circle\":\n",
    "    opt.num_domain = 2\n",
    "    opt.num_source = 1\n",
    "    opt.normalize_domain = False    \n",
    "elif opt.data == \"sine\":\n",
    "    opt.num_domain = 12\n",
    "    opt.num_source = 5\n",
    "    opt.normalize_domain = True  # normalize data per domain\n",
    "else:\n",
    "    assert False, \"Can't find data\"\n",
    "opt.num_target = opt.num_domain - opt.num_source\n",
    "\n",
    "# model specific configs\n",
    "\n",
    "opt.cond_disc = False  # use conditional discriminator\n",
    "opt.continual_da = False  # use continual domain adaptation\n",
    "\n",
    "opt.lambda_gan = 2.0\n",
    "\n",
    "if opt.model == 'CIDA':\n",
    "    opt.lambda_gan = 0.4\n",
    "\n",
    "elif opt.model == 'PCIDA':\n",
    "    opt.lambda_gan = 1.0\n",
    "    opt.nmix = 1  # number of mix guassian for the discriminator prediction\n",
    "    # opt.no_bn = False\n",
    "\n",
    "elif opt.model == \"MDD\":\n",
    "    opt.lambda_src = 1.0\n",
    "    opt.lambda_tgt = 1.0\n",
    "    opt.lambda_gan = 2.0\n",
    "    opt.num_epoch = 160  # early stop (optional) \n",
    "\n",
    "elif opt.model == 'CDANN':\n",
    "    opt.cond_disc = True\n",
    "\n",
    "elif opt.model == 'CUA':\n",
    "    opt.continual_da = True\n",
    "    opt.num_da_step = 5  # number of steps of domain adaptation\n",
    "    opt.num_epoch_pre = 10  # number of epochs of pretraining in source domain\n",
    "    opt.num_epoch_sub = 50  # number of epochs of adapting to a new sub target domain\n",
    "    opt.lr_decay_period = 500\n",
    "    opt.lambda_gan = 1.0\n",
    "    opt.lambda_rpy = 0.3\n",
    "\n",
    "opt.exp = opt.data + '_' + opt.model\n",
    "opt.outf = './dump/' + opt.exp\n",
    "os.system('mkdir -p ' + opt.outf)\n",
    "\n",
    "opt.use_resample = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "(3000,)\n",
      "SeqDataset Size 3000 Sub Size [3000, 3000]\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "from plot import plot_dataset\n",
    "import pandas as pd\n",
    "\n",
    "def select_columns(data_frame, column_names):\n",
    "    new_frame = data_frame.loc[:, column_names]\n",
    "    return new_frame\n",
    "\n",
    "#data_pkl = read_pickle(f'./data/{opt.data}.pkl')\n",
    "#data_pkl = X\n",
    "selected_columns = ['frame.time_epoch','frame.time_delta', 'frame.time_delta_displayed', 'frame.time_relative', 'frame.len', 'frame.cap_len', 'radiotap.length', 'radiotap.present.tsft', 'radiotap.present.flags', 'radiotap.present.channel', 'radiotap.present.dbm_antsignal', 'radiotap.present.antenna', 'radiotap.present.rxflags', 'radiotap.mactime', 'radiotap.flags.fcs', 'radiotap.datarate', 'radiotap.channel.freq', 'radiotap.channel.type.cck', 'radiotap.channel.type.ofdm','radiotap.channel.type.2ghz', 'radiotap.dbm_antsignal','radiotap.antenna', 'wlan.fc.type_subtype', 'wlan.fc.type', 'wlan.fc.subtype', 'wlan.fc.ds', 'wlan.fc.frag', 'wlan.fc.retry', 'wlan.fc.pwrmgt', 'wlan.fc.moredata', 'wlan.fc.protected', 'wlan.duration', 'wlan.ra', 'wlan.da', 'wlan.ta', 'wlan.sa', 'wlan.bssid', 'wlan.frag', 'wlan.seq', 'wlan.bar.type', 'wlan.ba.control.ackpolicy', 'wlan.ba.control.cbitmap', 'wlan.ba.bm', 'wlan.fcs_good', 'wlan_mgt.fixed.capabilities.ess', 'wlan_mgt.fixed.capabilities.ibss', 'wlan_mgt.fixed.capabilities.cfpoll.ap', 'wlan_mgt.fixed.capabilities.privacy', 'wlan_mgt.fixed.capabilities.preamble', 'wlan_mgt.fixed.capabilities.pbcc', 'wlan_mgt.fixed.capabilities.agility', 'wlan_mgt.fixed.capabilities.spec_man', 'wlan_mgt.fixed.capabilities.short_slot_time', 'wlan_mgt.fixed.capabilities.apsd', 'wlan_mgt.fixed.capabilities.radio_measurement', 'wlan_mgt.fixed.capabilities.dsss_ofdm', 'wlan_mgt.fixed.capabilities.del_blk_ack', 'wlan_mgt.fixed.capabilities.imm_blk_ack', 'wlan_mgt.fixed.listen_ival', 'wlan_mgt.fixed.current_ap', 'wlan_mgt.fixed.status_code', 'wlan_mgt.fixed.timestamp', 'wlan_mgt.fixed.beacon', 'wlan_mgt.fixed.aid', 'wlan_mgt.fixed.reason_code', 'wlan_mgt.fixed.auth.alg', 'wlan_mgt.fixed.auth_seq', 'wlan_mgt.fixed.sequence', 'wlan_mgt.tagged.all', 'wlan_mgt.ds.current_channel', 'wlan_mgt.tim.dtim_count', 'wlan_mgt.tim.dtim_period', 'wlan_mgt.tim.bmapctl.multicast', 'wlan_mgt.country_info.environment', 'wlan_mgt.rsn.version', 'wlan_mgt.rsn.gcs.type', 'wlan_mgt.rsn.pcs.count', 'wlan_mgt.rsn.akms.count', 'wlan_mgt.rsn.akms.type', 'wlan_mgt.rsn.capabilities.preauth', 'wlan_mgt.rsn.capabilities.ptksa_replay_counter', 'wlan_mgt.tcprep.trsmt_pow', 'wlan.wep.iv', 'wlan.wep.key', 'wlan.wep.icv','wlan.tkip.extiv', 'wlan.ccmp.extiv', 'wlan.qos.tid', 'wlan.qos.priority', 'data.len']\n",
    "\n",
    "data_df = select_columns(X, selected_columns)\n",
    "data= data_df.to_numpy()\n",
    "label=encoded_y\n",
    "\n",
    "data_df1= select_columns(X_test, selected_columns)\n",
    "data1= data_df1.to_numpy()\n",
    "label1=encoded_y_test\n",
    "\n",
    "\n",
    "#domain= data_pkl['domain']\n",
    "domain= np.empty((0))\n",
    "domain1= np.empty((0))\n",
    "for i in range(15):\n",
    "    for j in range(200):\n",
    "        domain = np.append(domain, 0)\n",
    "\n",
    "for i in range(15):\n",
    "    for j in range(200):\n",
    "        domain1 = np.append(domain1, 1)\n",
    "\n",
    "\n",
    "print(domain.shape)\n",
    "print(domain1.shape)\n",
    "\n",
    "#print(awid.data)\n",
    "#save to pickle file\n",
    "#with open('awid50.pkl', 'wb') as f:\n",
    "#    pickle.dump(awid, f)\n",
    "\n",
    "\n",
    "\n",
    "#create dictionary\n",
    "\n",
    "awid={\n",
    "    'data': data,\n",
    "    'label': label,\n",
    "    'domain': domain\n",
    "}\n",
    "awid1={\n",
    "    'data': data1,\n",
    "    'label': label1,\n",
    "    'domain': domain1\n",
    "}\n",
    "\n",
    "\n",
    "datasets = [ToyDataset(awid,  0, opt)]  # sub dataset for each domain\n",
    "datasets1 = [ToyDataset(awid1, 1, opt)] # sub dataset for each domain\n",
    "\n",
    "datasets_combined= [datasets[0],datasets1[0]]\n",
    "#datasets_combined= [datasets[0],datasets[1],datasets[2],datasets[3],datasets[4],datasets[5],datasets[6],datasets[7],datasets[8],datasets[9],datasets[10],datasets[11],datasets[12],datasets[13],datasets[14],datasets1[0],datasets1[1],datasets1[2],datasets1[3],datasets1[4],datasets1[5],datasets1[6],datasets1[7],datasets1[8],datasets1[9],datasets1[10],datasets1[11],datasets1[12],datasets1[13],datasets1[14]]\n",
    "dataset = SeqToyDataset(datasets_combined, size=len(datasets_combined[0]))  # mix sub dataset to a large one\n",
    "#dataset = SeqToyDataset(datasets, size=len(datasets[0]))  # mix sub dataset to a large one\n",
    "\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=opt.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'model.ADDA'>\n",
      "===> Discrinimator Output Activation: sigmoid\n",
      "ADDA(\n",
      "  (netE): FeatureNet(\n",
      "    (fc1): Linear(in_features=90, out_features=800, bias=True)\n",
      "    (fc2): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "    (fc3): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "    (fc4): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "    (fc_final): Linear(in_features=1600, out_features=800, bias=True)\n",
      "    (fc1_var): Linear(in_features=1, out_features=800, bias=True)\n",
      "    (fc2_var): Linear(in_features=800, out_features=800, bias=True)\n",
      "  )\n",
      "  (netF): PredNet(\n",
      "    (fc3): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (bn3): Identity()\n",
      "    (fc4): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (bn4): Identity()\n",
      "    (fc_final): Linear(in_features=800, out_features=4, bias=True)\n",
      "  )\n",
      "  (netD): DiscNet(\n",
      "    (fc3): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (bn3): Identity()\n",
      "    (fc4): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (bn4): Identity()\n",
      "    (fc5): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (bn5): Identity()\n",
      "    (fc6): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (bn6): Identity()\n",
      "    (fc7): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (bn7): Identity()\n",
      "    (fc_final): Linear(in_features=800, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "[Train][9] Loss: D 19.795 E_gan 17.484 E_pred 21089894.716\n",
      "[Train][9] Accuracy: total average 83.7, in each domain [87.  80.3]\n",
      "[Train][19] Loss: D 22.005 E_gan 20.125 E_pred 8142003.209\n",
      "[Train][19] Accuracy: total average 81.6, in each domain [85.2 78.1]\n",
      "[Train][29] Loss: D 13.583 E_gan 0.267 E_pred 62710.596\n",
      "[Train][29] Accuracy: total average 78.2, in each domain [67.2 89.1]\n",
      "[Train][39] Loss: D 23.026 E_gan 0.000 E_pred 1303326.322\n",
      "[Train][39] Accuracy: total average 83.2, in each domain [86.5 80. ]\n",
      "[Train][49] Loss: D 13.461 E_gan 0.269 E_pred 19594.983\n",
      "[Train][49] Accuracy: total average 77.9, in each domain [66.8 89. ]\n",
      "[Test][49] Accuracy: total average 78.4, in each domain [67.5 89.3]\n",
      "[Train][59] Loss: D 22.328 E_gan 0.009 E_pred 177651.858\n",
      "[Train][59] Accuracy: total average 72.9, in each domain [73.5 72.3]\n",
      "[Train][69] Loss: D 13.061 E_gan 0.307 E_pred 251.678\n",
      "[Train][69] Accuracy: total average 78.6, in each domain [69.1 88.2]\n",
      "[Train][79] Loss: D 12.851 E_gan 0.297 E_pred 0.621\n",
      "[Train][79] Accuracy: total average 78.2, in each domain [67.  89.4]\n",
      "[Train][89] Loss: D 12.851 E_gan 0.295 E_pred 0.612\n",
      "[Train][89] Accuracy: total average 78.3, in each domain [67.  89.5]\n",
      "[Train][99] Loss: D 15.660 E_gan 0.177 E_pred 0.566\n",
      "[Train][99] Accuracy: total average 78.2, in each domain [67.  89.5]\n",
      "[Test][99] Accuracy: total average 78.2, in each domain [67.  89.5]\n"
     ]
    }
   ],
   "source": [
    "from model import get_model\n",
    "\n",
    "# set random seed (for reproducibility)\n",
    "np.random.seed(opt.seed)\n",
    "random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "# build the model\n",
    "modelClass = get_model(opt.model)\n",
    "print(modelClass)\n",
    "model = modelClass(opt)\n",
    "model.to(opt.device)\n",
    "print(model)\n",
    "\n",
    "if opt.normalize_domain:\n",
    "    model.set_data_stats(\n",
    "        dm=[d.data_m for d in datasets],\n",
    "        ds=[d.data_s for d in datasets],\n",
    "    )\n",
    "    \n",
    "# train the model\n",
    "if not opt.continual_da:\n",
    "    # one-step adaptation\n",
    "    for epoch in range(opt.num_epoch):\n",
    "        model.learn(epoch, dataloader)\n",
    "        if (epoch + 1) % 100 == 0 or (epoch + 1) == opt.num_epoch:\n",
    "            model.save()\n",
    "            # model.visualize_D()\n",
    "            # model.visualize_F()\n",
    "            # model.visualize_E()\n",
    "        if (epoch + 1) % 50 == 0:    \n",
    "            model.test(epoch, dataloader)\n",
    "else:\n",
    "    # pretrain on source\n",
    "    print('===> pretrain the classifer')\n",
    "    model.prepare_trainer(init=True)\n",
    "    for epoch in range(opt.num_epoch_pre):\n",
    "        model.learn(epoch, dataloader, init=True)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.save()\n",
    "            model.visualize_F()\n",
    "            model.test(epoch, dataloader)\n",
    "    # step-by-step domain adapt\n",
    "    ds_size = len(datasets[0])\n",
    "    replay_datasets = [datasets[i] for i in range(opt.num_source)]\n",
    "    print('===> start continual DA')\n",
    "    model.prepare_trainer(init=False)\n",
    "    for phase in range(opt.num_source, opt.num_domain):\n",
    "        continual_dataset = SeqToyDataset(replay_datasets, size=ds_size)\n",
    "        continual_dataloader = DataLoader(\n",
    "            dataset=continual_dataset,\n",
    "            shuffle=True,\n",
    "            batch_size=opt.batch_size,\n",
    "            num_workers=4,\n",
    "        )\n",
    "        model.set_phase(phase)\n",
    "        for epoch in range(opt.num_epoch_sub):\n",
    "            model.learn(epoch, (dataloader, continual_dataloader), init=False)\n",
    "        # model.visualize_F(phase)\n",
    "        model.save()\n",
    "        model.test(epoch, dataloader)\n",
    "        replay_data, replay_label = model.gen_replay_dataset(dataloader)\n",
    "        replay_datasets.append(ReplayDataset(replay_data, replay_label, opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
