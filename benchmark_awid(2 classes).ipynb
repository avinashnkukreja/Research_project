{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "# supress warnings for clean output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.vae import VAE\n",
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "from pyod.models.so_gaal import SO_GAAL\n",
    "\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "with open('train.pk', 'rb') as f:\n",
    "    xx, yy = pickle.load(f)\n",
    "with open('test.pk', 'rb') as f:\n",
    "    X_test,y_test = pickle.load(f)\n",
    "X,Y = make_imbalance(xx, yy, sampling_strategy={'normal':2700, 'injection':100, 'impersonation':100, 'flooding':100},random_state=0)\n",
    "#xx, yy = make_imbalance(X, Y, sampling_strategy={'normal':3000, 'injection':1000, 'impersonation':1000, 'flooding':1000},random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(42)\n",
    "\n",
    "df_columns = ['Data', '#Samples', '# Dimensions', 'Outlier Perc',\n",
    "              'ABOD', 'CBLOF', 'FB', 'HBOS', 'IForest', 'KNN', 'LOF', 'MCD',\n",
    "              'OCSVM', 'PCA', 'AutoEncoder', 'VAE', 'MO_GAAL', 'SO_GAAL']\n",
    "roc_df = pd.DataFrame(columns=df_columns)\n",
    "prn_df = pd.DataFrame(columns=df_columns)\n",
    "time_df = pd.DataFrame(columns=df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.1\n",
    "outliers_percentage = 10\n",
    "\n",
    "X_train_norm, X_test_norm = X, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_y = encoder.fit_transform(Y)\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "binarized_y = binarizer.fit_transform(encoded_y)\n",
    "binarized_y.shape\n",
    "\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "\n",
    "y = keras.utils.to_categorical(encoded_y)\n",
    "y_test = keras.utils.to_categorical(encoded_y_test)\n",
    "print(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(encoded_y == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n",
      "300\n",
      "530785\n",
      "44858\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,encoded_y.shape[0]):\n",
    "    if encoded_y[i]==0:\n",
    "        encoded_y[i]=1\n",
    "    if encoded_y[i]==2:\n",
    "        encoded_y[i]=1\n",
    "for i in range(0,encoded_y.shape[0]):\n",
    "    if encoded_y[i]==3:\n",
    "        encoded_y[i]=0\n",
    "print(np.count_nonzero(encoded_y == 0))\n",
    "print(np.count_nonzero(encoded_y == 1))#outlier\n",
    "\n",
    "for i in range(0,encoded_y_test.shape[0]):\n",
    "    if encoded_y_test[i]==0:\n",
    "        encoded_y_test[i]=1\n",
    "    if encoded_y_test[i]==2:\n",
    "        encoded_y_test[i]=1\n",
    "for i in range(0,encoded_y_test.shape[0]):\n",
    "    if encoded_y_test[i]==3:\n",
    "        encoded_y_test[i]=0\n",
    "print(np.count_nonzero(encoded_y_test == 0))\n",
    "print(np.count_nonzero(encoded_y_test == 1))#outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,  confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle-based Outlier Detector (ABOD)\n",
      "Angle-based Outlier Detector (ABOD) Train dataset:\n",
      "ROC:0.3172, precision @ rank n:0.0633\n",
      "Test dataset:\n",
      "ROC:0.8229, precision @ rank n:0.2451\n",
      "Cluster-based Local Outlier Factor\n",
      "Cluster-based Local Outlier Factor Train dataset:\n",
      "ROC:0.7875, precision @ rank n:0.5133\n",
      "Test dataset:\n",
      "ROC:0.7994, precision @ rank n:0.3856\n",
      "Feature Bagging\n",
      "Feature Bagging Train dataset:\n",
      "ROC:0.5259, precision @ rank n:0.1933\n",
      "Test dataset:\n",
      "ROC:0.6719, precision @ rank n:0.0718\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Histogram-base Outlier Detection (HBOS) Train dataset:\n",
      "ROC:0.6638, precision @ rank n:0.0433\n",
      "Test dataset:\n",
      "ROC:0.5096, precision @ rank n:0.0071\n",
      "Isolation Forest\n",
      "Isolation Forest Train dataset:\n",
      "ROC:0.6963, precision @ rank n:0.05\n",
      "Test dataset:\n",
      "ROC:0.5941, precision @ rank n:0.0018\n",
      "K Nearest Neighbors (KNN)\n",
      "K Nearest Neighbors (KNN) Train dataset:\n",
      "ROC:0.3725, precision @ rank n:0.1003\n",
      "Test dataset:\n",
      "ROC:0.7118, precision @ rank n:0.2795\n",
      "Local Outlier Factor (LOF)\n",
      "Local Outlier Factor (LOF) Train dataset:\n",
      "ROC:0.5183, precision @ rank n:0.1\n",
      "Test dataset:\n",
      "ROC:0.6995, precision @ rank n:0.1873\n",
      "Minimum Covariance Determinant (MCD)\n",
      "Minimum Covariance Determinant (MCD) Train dataset:\n",
      "ROC:0.7271, precision @ rank n:0.25\n",
      "Test dataset:\n",
      "ROC:0.7541, precision @ rank n:0.0757\n",
      "One-class SVM (OCSVM)\n",
      "One-class SVM (OCSVM) Train dataset:\n",
      "ROC:0.4943, precision @ rank n:0.0\n",
      "Test dataset:\n",
      "ROC:0.5, precision @ rank n:0.0\n",
      "Principal Component Analysis (PCA)\n",
      "Principal Component Analysis (PCA) Train dataset:\n",
      "ROC:0.6107, precision @ rank n:0.0233\n",
      "Test dataset:\n",
      "ROC:0.5837, precision @ rank n:0.0027\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 153)               23562     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 153)               23562     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2464      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 153)               2601      \n",
      "=================================================================\n",
      "Total params: 52,541\n",
      "Trainable params: 52,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 12.7738 - val_loss: 4.9876\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.7080 - val_loss: 2.2291\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 4.0966 - val_loss: 1.5694\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 2.7778 - val_loss: 1.2108\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 2.0457 - val_loss: 1.0056\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5747 - val_loss: 0.8768\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.3143 - val_loss: 0.7971\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1414 - val_loss: 0.7416\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0349 - val_loss: 0.7061\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9533 - val_loss: 0.6728\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8959 - val_loss: 0.6505\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.8584 - val_loss: 0.6344\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.8223 - val_loss: 0.6176\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7973 - val_loss: 0.6050\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7767 - val_loss: 0.5945\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7590 - val_loss: 0.5849\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7450 - val_loss: 0.5767\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7341 - val_loss: 0.5694\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.7262 - val_loss: 0.5628\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7170 - val_loss: 0.5568\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7080 - val_loss: 0.5511\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7023 - val_loss: 0.5459\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6972 - val_loss: 0.5410\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6888 - val_loss: 0.5359\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.6849 - val_loss: 0.5316\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6798 - val_loss: 0.5278\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6767 - val_loss: 0.5239\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.6717 - val_loss: 0.5203\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6676 - val_loss: 0.5168\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6629 - val_loss: 0.5132\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6613 - val_loss: 0.5106\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6578 - val_loss: 0.5077\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6548 - val_loss: 0.5051\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.6521 - val_loss: 0.5022\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6487 - val_loss: 0.4996\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.6448 - val_loss: 0.4968\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6446 - val_loss: 0.4950\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6400 - val_loss: 0.4925\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6381 - val_loss: 0.4904\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6350 - val_loss: 0.4878\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6329 - val_loss: 0.4858\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6309 - val_loss: 0.4839\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6284 - val_loss: 0.4824\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6274 - val_loss: 0.4806\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 0.6251 - val_loss: 0.4787\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 0.4767\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6213 - val_loss: 0.4753\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6196 - val_loss: 0.4737\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 0.4722\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 0.4707\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6145 - val_loss: 0.4693\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 0.4679\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6122 - val_loss: 0.4666\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6094 - val_loss: 0.4653\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.4639\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.4626\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 0.4617\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.4602\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.4594\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.4581\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 0.4570\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5987 - val_loss: 0.4559\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5977 - val_loss: 0.4550\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5967 - val_loss: 0.4539\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5954 - val_loss: 0.4529\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5945 - val_loss: 0.4521\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5935 - val_loss: 0.4512\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5924 - val_loss: 0.4502\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.5917 - val_loss: 0.4495\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5906 - val_loss: 0.4486\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5893 - val_loss: 0.4477\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5889 - val_loss: 0.4470\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5876 - val_loss: 0.4461\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5869 - val_loss: 0.4454\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5862 - val_loss: 0.4446\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5851 - val_loss: 0.4439\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5842 - val_loss: 0.4431\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5835 - val_loss: 0.4424\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5823 - val_loss: 0.4417\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5818 - val_loss: 0.4412\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5812 - val_loss: 0.4406\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5804 - val_loss: 0.4399\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5799 - val_loss: 0.4393\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.5791 - val_loss: 0.4386\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.5787 - val_loss: 0.4381\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5779 - val_loss: 0.4377\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5775 - val_loss: 0.4371\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5766 - val_loss: 0.4365\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.5762 - val_loss: 0.4360\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.5754 - val_loss: 0.4354\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.5746 - val_loss: 0.4349\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.5742 - val_loss: 0.4345\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5738 - val_loss: 0.4340\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5732 - val_loss: 0.4335\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5728 - val_loss: 0.4331\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5722 - val_loss: 0.4326\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5715 - val_loss: 0.4322\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5714 - val_loss: 0.4318\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5706 - val_loss: 0.4314\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5703 - val_loss: 0.4310\n",
      "Auto Encoder\n",
      "Auto Encoder Train dataset:\n",
      "ROC:0.6142, precision @ rank n:0.0233\n",
      "Test dataset:\n",
      "ROC:0.5864, precision @ rank n:0.0027\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 153)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 153)          23562       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           2464        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 8)            136         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           144         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            34          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            34          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 2)            0           dense_11[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 26,374\n",
      "Trainable params: 26,374\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 153)               2601      \n",
      "=================================================================\n",
      "Total params: 2,935\n",
      "Trainable params: 2,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 153)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       [(None, 2), (None, 2 26374       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 153)          2935        functional_1[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 153)          23562       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           2464        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 8)            136         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           144         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            34          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            34          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 2)]          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None, 2)]          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 2)]          0           tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_Square[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp (TensorFlowOpLa [(None, 2)]          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 2)]          0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 tf_op_layer_Exp[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None,)]            0           tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None,)]            0           tf_op_layer_Sum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SquaredDifference ( [(None, 153)]        0           functional_3[0][0]               \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_2 (TensorFlowOp [(None,)]            0           tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None,)]            0           tf_op_layer_SquaredDifference[0][\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Abs (TensorFlowOpLa [(None,)]            0           tf_op_layer_Sub_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None,)]            0           tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [(None,)]            0           tf_op_layer_Abs[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None,)]            0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 tf_op_layer_Mul_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [()]                 0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf_op_layer_Mean_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 29,309\n",
      "Trainable params: 29,309\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 137.0213 - val_loss: 84.0899\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 92.7794 - val_loss: 66.1230\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 86.2873 - val_loss: 65.7332\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 85.5054 - val_loss: 65.6506\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.1619 - val_loss: 65.6592\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0991 - val_loss: 65.6091\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0213 - val_loss: 65.5777\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9394 - val_loss: 65.5843\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 85.0136 - val_loss: 65.5773\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.8144 - val_loss: 65.5692\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8891 - val_loss: 65.5726\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7850 - val_loss: 65.5709\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.9646 - val_loss: 65.5689\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 90.3274 - val_loss: 65.5664\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 85.1461 - val_loss: 65.5692\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9057 - val_loss: 65.5689\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9194 - val_loss: 65.5687\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 3ms/step - loss: 84.8048 - val_loss: 65.5659\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.9249 - val_loss: 65.5676\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7929 - val_loss: 65.5677\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9952 - val_loss: 65.5669\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0663 - val_loss: 65.5691\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8076 - val_loss: 65.5691\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 85.1333 - val_loss: 65.5682\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.2834 - val_loss: 65.5673\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8345 - val_loss: 65.5675\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.2667 - val_loss: 65.5662\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7644 - val_loss: 65.5672\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9843 - val_loss: 65.5676\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8011 - val_loss: 65.5676\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0707 - val_loss: 65.5666\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.9061 - val_loss: 65.5670\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7978 - val_loss: 65.5673\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7674 - val_loss: 65.5677\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9660 - val_loss: 65.5670\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 96.6085 - val_loss: 65.5678\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 85.3513 - val_loss: 65.5673\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.8605 - val_loss: 65.5679\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.7974 - val_loss: 65.5679\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 96.4796 - val_loss: 65.5674\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8074 - val_loss: 65.5671\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9697 - val_loss: 65.5674\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.1702 - val_loss: 65.5678\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7863 - val_loss: 65.5672\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 96.4338 - val_loss: 65.5668\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8064 - val_loss: 65.5677\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0353 - val_loss: 65.5672\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 90.5568 - val_loss: 65.5674\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9458 - val_loss: 65.5676\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9135 - val_loss: 65.5675\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9837 - val_loss: 65.5673\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8567 - val_loss: 65.5674\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0375 - val_loss: 65.5675\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 96.2819 - val_loss: 65.5675\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 85.0969 - val_loss: 65.5673\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 85.4983 - val_loss: 65.5675\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.9098 - val_loss: 65.5673\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0918 - val_loss: 65.5673\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8663 - val_loss: 65.5674\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.8911 - val_loss: 65.5674\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7625 - val_loss: 65.5675\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7815 - val_loss: 65.5674\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.4789 - val_loss: 65.5673\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7834 - val_loss: 65.5674\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7902 - val_loss: 65.5674\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8436 - val_loss: 65.5673\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9976 - val_loss: 65.5674\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0070 - val_loss: 65.5673\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8077 - val_loss: 65.5674\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9901 - val_loss: 65.5673\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9146 - val_loss: 65.5674\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.9563 - val_loss: 65.5674\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 84.8880 - val_loss: 65.5674\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8031 - val_loss: 65.5674\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7757 - val_loss: 65.5674\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.2926 - val_loss: 65.5674\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0566 - val_loss: 65.5674\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 84.8343 - val_loss: 65.5674\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0581 - val_loss: 65.5674\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9217 - val_loss: 65.5674\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8005 - val_loss: 65.5674\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0830 - val_loss: 65.5674\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8495 - val_loss: 65.5674\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9686 - val_loss: 65.5674\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 86.5615 - val_loss: 65.5673\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.1944 - val_loss: 65.5674\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9093 - val_loss: 65.5674\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.7877 - val_loss: 65.5674\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8732 - val_loss: 65.5674\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.1496 - val_loss: 65.5674\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0514 - val_loss: 65.5673\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.1104 - val_loss: 65.5674\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.1687 - val_loss: 65.5674\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.0341 - val_loss: 65.5674\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.1101 - val_loss: 65.5674\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 85.8057 - val_loss: 65.5674\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9201 - val_loss: 65.5674\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 3ms/step - loss: 87.5140 - val_loss: 65.5674\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.8564 - val_loss: 65.5674\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 84.9927 - val_loss: 65.5674\n",
      "VAE\n",
      "VAE Train dataset:\n",
      "ROC:0.6107, precision @ rank n:0.0233\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ddb6acdef02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtest_scores1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mroc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_n_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyod/models/vae.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;31m# Predict on X and return the reconstruction errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mpred_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpairwise_distances_no_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyod/utils/stat_models.py\u001b[0m in \u001b[0;36mpairwise_distances_no_broadcast\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "    classifiers = {'Angle-based Outlier Detector (ABOD)': ABOD(\n",
    "        contamination=outliers_fraction),\n",
    "        'Cluster-based Local Outlier Factor': CBLOF(\n",
    "            contamination=outliers_fraction, check_estimator=False,\n",
    "            random_state=random_state),\n",
    "        'Feature Bagging': FeatureBagging(contamination=outliers_fraction,\n",
    "                                          random_state=random_state),\n",
    "        'Histogram-base Outlier Detection (HBOS)': HBOS(\n",
    "            contamination=outliers_fraction),\n",
    "        'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "                                    random_state=random_state),\n",
    "        'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),\n",
    "        'Local Outlier Factor (LOF)': LOF(\n",
    "            contamination=outliers_fraction),\n",
    "        'Minimum Covariance Determinant (MCD)': MCD(\n",
    "            contamination=outliers_fraction, random_state=random_state),\n",
    "        'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),\n",
    "        'Principal Component Analysis (PCA)': PCA(\n",
    "            contamination=outliers_fraction, random_state=random_state),\n",
    "                   \n",
    "        'Auto Encoder': AutoEncoder(contamination=outliers_fraction, random_state=random_state, hidden_neurons= [16,8,8,16]),\n",
    "         'VAE': VAE(contamination=outliers_fraction, random_state=random_state, encoder_neurons= [16,8,16], decoder_neurons= [16,8,16]),\n",
    "        'MO_GAAL': MO_GAAL(contamination=outliers_fraction),\n",
    "        'SO_GAAL': SO_GAAL(contamination=outliers_fraction)\n",
    "    }\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_train_norm)\n",
    "        \n",
    "        test_scores = clf.decision_function(X_train_norm)\n",
    "        roc = round(roc_auc_score(encoded_y, test_scores), ndigits=4)\n",
    "        prn = round(precision_n_scores(encoded_y, test_scores), ndigits=4)\n",
    "        print(clf_name)\n",
    "        print(clf_name,\"Train dataset:\")\n",
    "        print('ROC:{roc}, precision @ rank n:{prn}'.format(roc=roc, prn=prn))\n",
    "        \n",
    "        \n",
    "        test_scores1 = clf.decision_function(X_test_norm)\n",
    "        roc1 = round(roc_auc_score(encoded_y_test, test_scores1), ndigits=4)\n",
    "        prn1 = round(precision_n_scores(encoded_y_test, test_scores1), ndigits=4)\n",
    "        print(\"Test dataset:\")\n",
    "        print('ROC:{roc1}, precision @ rank n:{prn1}'.format(roc1=roc1, prn1=prn1))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
