{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install / upgrade necessary packages\n",
    "# !pip install easydict\n",
    "# !pip install numpy\n",
    "# !pip install numpy --upgrade # upgrade numpy to at least 1.19\n",
    "# !pip install torch --upgrade # upgrade pytorch to 1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "args = EasyDict()\n",
    "\n",
    "args.epochs=16\n",
    "args.dropout=0.0\n",
    "args.lr=5e-5\n",
    "args.gamma_exp=1000\n",
    "args.hidden=800\n",
    "args.ratio=1\n",
    "args.dis_lambda=1.0\n",
    "args.lambda_m=0.0\n",
    "args.wgan='wgan'\n",
    "args.clamp_lower=-0.15\n",
    "args.clamp_upper=0.15\n",
    "args.batch_size=100\n",
    "args.num_train=100\n",
    "args.loss='default'\n",
    "args.evaluate=False\n",
    "args.checkpoint='none'\n",
    "args.save_head='tmp'\n",
    "args.save_interval=20\n",
    "args.log_interval=20\n",
    "args.log_file='tmp_mlp'\n",
    "args.seed=2 #2\n",
    "args.cuda=False\n",
    "args.device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.18.5\n",
      "Pytorch version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from utils import plain_log\n",
    "from utils import write_pickle,read_pickle\n",
    "from utils import masked_cross_entropy\n",
    "from utils import gaussian_loss\n",
    "from torch.utils import data\n",
    "from data_loader import toydata\n",
    "import pandas as pd\n",
    "\n",
    "label_noise_std = 0.50\n",
    "use_label_noise = False\n",
    "use_inverse_weighted = True\n",
    "discr_thres = 999.999\n",
    "normalize = True\n",
    "train_discr_step_tot = 2\n",
    "train_discr_step_extra = 0\n",
    "slow_lrD_decay = 1\n",
    "norm = 8\n",
    "fname_save = 'pred_tmp.pkl'\n",
    "fname = '/Users/avin/Desktop/Intrusion Detection/Datasets/awid_4class.pkl'\n",
    "fname_test='/Users/avin/Desktop/Intrusion Detection/Datasets/awid_4class.pkl'\n",
    "data = read_pickle(fname_test)\n",
    "true_class=data['label']\n",
    "train_list = list(range(2))\n",
    "mask_list = [1] + [0] \n",
    "test_list = list(range(2))\n",
    "cm= False\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(int(args.seed))\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    toydata(fname, train_list, normalize, mask_list),\n",
    "    shuffle=True,\n",
    "    batch_size=args.batch_size, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    toydata(fname_test, test_list, normalize),\n",
    "    batch_size=args.batch_size, **kwargs)\n",
    "\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Pytorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data and plot it for visualization only\n",
    "#from plot import plot_dataset\n",
    "#import matplotlib.pyplot as plt\n",
    "#data_pkl = read_pickle(f'./awid.pkl')\n",
    "#plot_dataset(data_pkl)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder: domain as input to generate feature, and then concatenate, deep dynamic layers\n",
    "class DomainEnc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DomainEnc, self).__init__()\n",
    "        self.hidden = args.hidden\n",
    "        self.ratio = float(args.ratio)\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "        self.fc1 = nn.Linear(153, self.hidden)\n",
    "        self.drop1 = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc2 = nn.Linear(self.hidden + int(self.hidden // self.ratio), self.hidden + int(self.hidden // self.ratio))\n",
    "        self.drop2 = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc3 = nn.Linear(self.hidden + int(self.hidden // self.ratio), self.hidden + int(self.hidden // self.ratio))\n",
    "        self.drop3 = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc4 = nn.Linear(self.hidden + int(self.hidden // self.ratio), self.hidden + int(self.hidden // self.ratio))\n",
    "        self.drop4 = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc_final = nn.Linear(self.hidden + int(self.hidden // self.ratio), self.hidden)\n",
    "\n",
    "        self.fc1_var = nn.Linear(1, int(self.hidden // self.ratio))\n",
    "        self.fc2_var = nn.Linear(int(self.hidden // self.ratio), int(self.hidden // self.ratio))\n",
    "        self.fc3_var = nn.Linear(int(self.hidden // self.ratio), int(self.hidden // self.ratio))\n",
    "        self.drop1_var = nn.Dropout(self.dropout)\n",
    "        self.drop2_var = nn.Dropout(self.dropout)\n",
    "        self.drop3_var = nn.Dropout(self.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, domain = x\n",
    "        domain = domain.unsqueeze(1) / norm\n",
    "\n",
    "        # side branch for variable FC\n",
    "        x_domain = F.relu(self.fc1_var(domain))\n",
    "        x_domain = self.drop1_var(x_domain)\n",
    "\n",
    "        # main branch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        # combine feature in the middle\n",
    "        x = torch.cat((x, x_domain), dim=1)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.drop3(x)\n",
    "\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.drop4(x)\n",
    "\n",
    "        # continue main branch\n",
    "        x = F.relu(self.fc_final(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor\n",
    "class DomainPred(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DomainPred, self).__init__()\n",
    "        self.hidden = args.hidden\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "        self.drop0 = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.hidden, self.hidden)\n",
    "        self.drop1 = nn.Dropout(self.dropout)\n",
    "\n",
    "\n",
    "        self.fc_final = nn.Linear(self.hidden, 153)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, domain = x\n",
    "        domain = domain.unsqueeze(1) / norm\n",
    "\n",
    "        x = self.drop0(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        x = self.fc_final(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator: with BN layers after each FC, dual output\n",
    "class DomainDDisc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DomainDDisc, self).__init__()\n",
    "        self.hidden = args.hidden\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "        self.drop2 = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc3_m = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn3_m = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop3_m = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc3_s = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn3_s = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop3_s = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc4_m = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn4_m = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop4_m = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc4_s = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn4_s = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop4_s = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc5_m = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn5_m = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop5_m = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc5_s = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn5_s = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop5_s = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc6_m = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn6_m = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop6_m = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc6_s = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn6_s = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop6_s = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc7_m = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn7_m = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop7_m = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc7_s = nn.Linear(self.hidden, self.hidden)\n",
    "        self.bn7_s = nn.BatchNorm1d(self.hidden)\n",
    "        self.drop7_s = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.fc_final_m = nn.Linear(self.hidden, 1)\n",
    "        self.fc_final_s = nn.Linear(self.hidden, 1)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x, domain = x\n",
    "        domain = domain.unsqueeze(1) / norm\n",
    "\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x_m = F.relu(self.bn3_m(self.fc3_m(x)))\n",
    "        x_m = self.drop3_m(x_m)\n",
    "\n",
    "        x_s = F.relu(self.bn3_s(self.fc3_s(x)))\n",
    "        x_s = self.drop3_s(x_s)\n",
    "\n",
    "        x_m = F.relu(self.bn4_m(self.fc4_m(x_m)))\n",
    "        x_m = self.drop4_m(x_m)\n",
    "\n",
    "        x_s = F.relu(self.bn4_s(self.fc4_s(x_s)))\n",
    "        x_s = self.drop4_s(x_s)\n",
    "\n",
    "        x_m = F.relu(self.bn5_m(self.fc5_m(x_m)))\n",
    "        x_m = self.drop5_m(x_m)\n",
    "\n",
    "        x_s = F.relu(self.bn5_s(self.fc5_s(x_s)))\n",
    "        x_s = self.drop5_s(x_s)\n",
    "\n",
    "        x_m = F.relu(self.bn6_m(self.fc6_m(x_m)))\n",
    "        x_m = self.drop6_m(x_m)\n",
    "\n",
    "        x_s = F.relu(self.bn6_s(self.fc6_s(x_s)))\n",
    "        x_s = self.drop6_s(x_s)\n",
    "\n",
    "        x_m = F.relu(self.bn7_m(self.fc7_m(x_m)))\n",
    "        x_m = self.drop7_m(x_m)\n",
    "\n",
    "        x_s = F.relu(self.bn7_s(self.fc7_s(x_s)))\n",
    "        x_s = self.drop7_s(x_s)\n",
    "\n",
    "        x_m = self.fc_final_m(x_m)\n",
    "        x_s = self.fc_final_s(x_s) # log sigma^2\n",
    "\n",
    "        return (x_m, x_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "encoder = DomainEnc()\n",
    "predictor = DomainPred()\n",
    "discriminator = DomainDDisc()\n",
    "models = [encoder, predictor, discriminator]\n",
    "if args.cuda:\n",
    "    for model in models:\n",
    "        model.cuda()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: avg_discr_loss = 0.05547, avg_pred_loss = 7019384428.800, avg_total_loss = 7019384428.800,\n",
      "Test set: Average loss: 2252473658.03, Accuracy: 2740/3000 (91.33%), Precision: 0.91%, Recall: 0.90%, f1: 0.90%\n",
      "Train Epoch 2: avg_discr_loss = -0.09874, avg_pred_loss = 2300873010.133, avg_total_loss = 2300873010.133,\n",
      "Test set: Average loss: 3310872046.25, Accuracy: 2620/3000 (87.33%), Precision: 0.88%, Recall: 0.83%, f1: 0.85%\n",
      "Train Epoch 3: avg_discr_loss = -0.20398, avg_pred_loss = 2124752679.467, avg_total_loss = 2124752679.467,\n",
      "Test set: Average loss: 2009897462.44, Accuracy: 2696/3000 (89.87%), Precision: 0.89%, Recall: 0.91%, f1: 0.89%\n",
      "Train Epoch 4: avg_discr_loss = -0.30507, avg_pred_loss = 1129966342.400, avg_total_loss = 1129966342.400,\n",
      "Test set: Average loss: 832412362.75, Accuracy: 2616/3000 (87.20%), Precision: 0.90%, Recall: 0.83%, f1: 0.83%\n",
      "Train Epoch 5: avg_discr_loss = -0.40370, avg_pred_loss = 1197786776.533, avg_total_loss = 1197786776.533,\n",
      "Test set: Average loss: 942917281.79, Accuracy: 2777/3000 (92.57%), Precision: 0.91%, Recall: 0.93%, f1: 0.92%\n",
      "Train Epoch 6: avg_discr_loss = -0.50074, avg_pred_loss = 1366614455.467, avg_total_loss = 1366614455.467,\n",
      "Test set: Average loss: 1262092004.01, Accuracy: 2362/3000 (78.73%), Precision: 0.87%, Recall: 0.72%, f1: 0.68%\n",
      "Train Epoch 7: avg_discr_loss = -0.60400, avg_pred_loss = 1235760566.400, avg_total_loss = 1235760566.400,\n",
      "Test set: Average loss: 791511605.25, Accuracy: 2595/3000 (86.50%), Precision: 0.86%, Recall: 0.85%, f1: 0.85%\n",
      "Train Epoch 8: avg_discr_loss = -0.69892, avg_pred_loss = 1159631095.467, avg_total_loss = 1159631095.467,\n",
      "Test set: Average loss: 804436602.54, Accuracy: 2630/3000 (87.67%), Precision: 0.88%, Recall: 0.85%, f1: 0.85%\n",
      "Train Epoch 9: avg_discr_loss = -0.78395, avg_pred_loss = 988708581.067, avg_total_loss = 988708581.067,\n",
      "Test set: Average loss: 568589477.21, Accuracy: 2768/3000 (92.27%), Precision: 0.91%, Recall: 0.93%, f1: 0.91%\n",
      "Train Epoch 10: avg_discr_loss = -0.84696, avg_pred_loss = 722850467.200, avg_total_loss = 722850467.200,\n",
      "Test set: Average loss: 965511647.23, Accuracy: 2736/3000 (91.20%), Precision: 0.91%, Recall: 0.90%, f1: 0.90%\n",
      "Train Epoch 11: avg_discr_loss = -0.88676, avg_pred_loss = 617501234.667, avg_total_loss = 617501234.667,\n",
      "Test set: Average loss: 1086671752.53, Accuracy: 2389/3000 (79.63%), Precision: 0.63%, Recall: 0.71%, f1: 0.67%\n",
      "Train Epoch 12: avg_discr_loss = -0.90577, avg_pred_loss = 838040319.467, avg_total_loss = 838040319.467,\n",
      "Test set: Average loss: 892380225.54, Accuracy: 2708/3000 (90.27%), Precision: 0.89%, Recall: 0.90%, f1: 0.89%\n",
      "Train Epoch 13: avg_discr_loss = -0.91298, avg_pred_loss = 606942039.733, avg_total_loss = 606942039.733,\n",
      "Test set: Average loss: 330169432.06, Accuracy: 2765/3000 (92.17%), Precision: 0.91%, Recall: 0.92%, f1: 0.91%\n",
      "Train Epoch 14: avg_discr_loss = -0.91497, avg_pred_loss = 382955312.000, avg_total_loss = 382955312.000,\n",
      "Test set: Average loss: 229283645.44, Accuracy: 2762/3000 (92.07%), Precision: 0.91%, Recall: 0.92%, f1: 0.91%\n",
      "Train Epoch 15: avg_discr_loss = -0.91544, avg_pred_loss = 346547139.867, avg_total_loss = 346547139.867,\n",
      "Test set: Average loss: 799606870.02, Accuracy: 2728/3000 (90.93%), Precision: 0.90%, Recall: 0.89%, f1: 0.90%\n",
      "Train Epoch 16: avg_discr_loss = -0.91651, avg_pred_loss = 469075493.333, avg_total_loss = 469075493.333,\n",
      "Test set: Average loss: 392202489.34, Accuracy: 2781/3000 (92.70%), Precision: 0.92%, Recall: 0.92%, f1: 0.92%\n",
      "Test set: Average loss: 392202489.34, Accuracy: 2781/3000 (92.70%), Precision: 0.92%, Recall: 0.92%, f1: 0.92%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Set up optimizer\n",
    "opt_D = optim.Adam(discriminator.parameters(), lr = args.lr) # lr \n",
    "opt_non_D = optim.Adam(list(encoder.parameters()) + list(predictor.parameters()), lr = args.lr) # lr \n",
    "lr_scheduler_D = lr_scheduler.ExponentialLR(optimizer=opt_D, gamma=0.5 ** (1/(args.gamma_exp*(train_discr_step_extra+1)) * slow_lrD_decay))\n",
    "lr_scheduler_non_D = lr_scheduler.ExponentialLR(optimizer=opt_non_D, gamma=0.5 ** (1/args.gamma_exp))\n",
    "\n",
    "ind = list(range(args.batch_size))\n",
    "ind_test = list(range(1000))\n",
    "bce = nn.BCELoss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "def train(epoch):\n",
    "    for model in models:\n",
    "        model.train()\n",
    "    sum_discr_loss = 0\n",
    "    sum_total_loss = 0\n",
    "    sum_pred_loss = 0\n",
    "    for batch_idx, data_tuple in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data_tuple = tuple(ele.cuda() for ele in data_tuple)\n",
    "        if normalize:\n",
    "            data_raw, target, domain, data, mask = data_tuple\n",
    "        else:\n",
    "            data, target, domain, mask = data_tuple\n",
    "\n",
    "        # FF encoder and predictor\n",
    "        encoding = encoder((data, domain))\n",
    "        prediction = predictor((encoding, domain))\n",
    "\n",
    "        if use_label_noise:\n",
    "            noise = (torch.randn(domain.size()).cuda() * label_noise_std).unsqueeze(1)\n",
    "\n",
    "        # train discriminator\n",
    "        train_discr_step = 0\n",
    "        while args.dis_lambda > 0.0:\n",
    "            train_discr_step += 1\n",
    "            discr_pred_m, discr_pred_s = discriminator((encoding, domain))\n",
    "            discr_loss = gaussian_loss(discr_pred_m, discr_pred_s, domain.unsqueeze(1) / norm, np.mean(train_list) / norm, norm)\n",
    "            for model in models:\n",
    "                model.zero_grad()\n",
    "            discr_loss.backward(retain_graph=True)\n",
    "            opt_D.step()\n",
    "\n",
    "            # handle extra steps to train the discr's variance branch\n",
    "            if train_discr_step_extra > 0:\n",
    "                cur_extra_step = 0\n",
    "                while True:\n",
    "                    discr_pred_m, discr_pred_s = discriminator((encoding, domain))\n",
    "                    discr_loss = gaussian_loss(discr_pred_m.detach(), discr_pred_s, domain.unsqueeze(1) / norm)\n",
    "                    for model in models:\n",
    "                        model.zero_grad()\n",
    "                    discr_loss.backward(retain_graph=True)\n",
    "                    opt_D.step()\n",
    "                    cur_extra_step += 1\n",
    "                    if cur_extra_step > train_discr_step_extra:\n",
    "                        break\n",
    "\n",
    "            if discr_loss.item() < 1.1 * discr_thres and train_discr_step >= train_discr_step_tot:\n",
    "                sum_discr_loss += discr_loss.item()\n",
    "                break\n",
    "\n",
    "        # handle wgan\n",
    "        if args.wgan == 'wgan':\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(args.clamp_lower, args.clamp_upper)\n",
    "\n",
    "        # train encoder and predictor\n",
    "        pred_loss = masked_cross_entropy(prediction, target, mask)\n",
    "        discr_pred_m, discr_pred_s = discriminator((encoding, domain))\n",
    "        ent_loss = 0\n",
    "\n",
    "        discr_loss = gaussian_loss(discr_pred_m, discr_pred_s, domain.unsqueeze(1) / norm)\n",
    "        total_loss = pred_loss - discr_loss * args.dis_lambda\n",
    "\n",
    "        for model in models:\n",
    "            model.zero_grad()\n",
    "        total_loss.backward()\n",
    "        opt_non_D.step()\n",
    "        sum_pred_loss += pred_loss.item()\n",
    "        sum_total_loss += total_loss.item()\n",
    "\n",
    "    lr_scheduler_D.step()\n",
    "    lr_scheduler_non_D.step()\n",
    "\n",
    "    avg_discr_loss = sum_discr_loss / len(train_loader.dataset) * args.batch_size\n",
    "    avg_pred_loss = sum_pred_loss / len(train_loader.dataset) * args.batch_size\n",
    "    avg_total_loss = sum_total_loss / len(train_loader.dataset) * args.batch_size\n",
    "    log_txt = 'Train Epoch {}: avg_discr_loss = {:.5f}, avg_pred_loss = {:.3f}, avg_total_loss = {:.3f},'.format(epoch, avg_discr_loss, avg_pred_loss, avg_total_loss)\n",
    "    print(log_txt)\n",
    "    plain_log(args.log_file,log_txt+'\\n')\n",
    "    if epoch % args.save_interval == 0 and epoch != 0:\n",
    "        torch.save(encoder, '%s.model_enc' % args.save_head)\n",
    "        torch.save(predictor, '%s.model_pred' % args.save_head)\n",
    "        torch.save(discriminator, '%s.model_discr' % args.save_head)\n",
    "\n",
    "# Testing loop\n",
    "def test():\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    test_loss = 0\n",
    "    rmse_loss = 0\n",
    "    correct = 0\n",
    "    l_data = []\n",
    "    l_label = []\n",
    "    l_gt = []\n",
    "    l_encoding = []\n",
    "    l_domain = []\n",
    "    l_prob = []\n",
    "    #for data, target, domain in test_loader:\n",
    "    for data_tuple in test_loader:\n",
    "        if args.cuda:\n",
    "            data_tuple = tuple(ele.cuda() for ele in data_tuple)\n",
    "        if normalize:\n",
    "            data_raw, target, domain, data = data_tuple\n",
    "        else:\n",
    "            data, target, domain = data_tuple\n",
    "            data_raw = data\n",
    "        encoding = encoder((data, domain))\n",
    "        prediction = predictor((encoding, domain))\n",
    "        test_loss += F.nll_loss(prediction, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = prediction.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).cpu().sum()\n",
    "##\n",
    "        l_data.append(data_raw.cpu().numpy())\n",
    "        l_label.append(pred.cpu().numpy())\n",
    "        l_gt.append(target.cpu().numpy())\n",
    "        l_encoding.append(encoding.data.cpu().numpy())\n",
    "        l_domain.append(domain.data.cpu().numpy())\n",
    "        l_prob.append(prediction.data.cpu().numpy())\n",
    "\n",
    "    data_all = np.concatenate(l_data, axis=0)\n",
    "    label_all = np.concatenate(l_label, axis=0)\n",
    "    gt_all = np.concatenate(l_gt, axis=0)\n",
    "    encoding_all = np.concatenate(l_encoding, axis=0)\n",
    "    domain_all = np.concatenate(l_domain, axis=0)\n",
    "    prob_all = np.concatenate(l_prob, axis=0)\n",
    "    d_pkl = dict()\n",
    "    d_pkl['data'] = data_all\n",
    "    d_pkl['label'] = label_all[:, 0]\n",
    "    d_pkl['gt'] = gt_all\n",
    "    d_pkl['encoding'] = encoding_all\n",
    "    d_pkl['domain'] = domain_all\n",
    "    d_pkl['prob'] = prob_all\n",
    "    write_pickle(d_pkl, fname_save)\n",
    "    \n",
    "    p=np.asarray(label_all)\n",
    "    x=pd.DataFrame(p.flatten(),columns = ['col1'])\n",
    "    predicted_class=x['col1'].to_numpy()\n",
    "\n",
    "    pre= precision_score(true_class, predicted_class, average= 'macro')\n",
    "    recall= recall_score(true_class, predicted_class, average= 'macro')\n",
    "    f1= f1_score(true_class, predicted_class, average= 'macro')\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    log_txt = 'Test set: Average loss: {:.2f}, Accuracy: {}/{} ({:.2f}%), Precision: {:.2f}%, Recall: {:.2f}%, f1: {:.2f}%'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset), pre, recall, f1)\n",
    "    print(log_txt)\n",
    "    if(cm==True):\n",
    "        conf=confusion_matrix(true_class,predicted_class)\n",
    "        ax= plt.subplot()\n",
    "        sns.heatmap(conf, annot=True, ax = ax, fmt=\".1f\")\n",
    "        ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "        ax.set_title('Confusion Matrix'); \n",
    "        ax.xaxis.set_ticklabels(['Flooding', 'Impersination', 'Injection', 'Normal']); ax.yaxis.set_ticklabels(['Flooding', 'Impersination', 'Injection', 'Normal']);\n",
    "        plt.show()\n",
    "\n",
    "    plain_log(args.log_file,log_txt+'\\n')\n",
    "\n",
    "if args.checkpoint != 'none':\n",
    "    encoder = torch.load(args.checkpoint + '_enc')\n",
    "    predictor = torch.load(args.checkpoint + '_pred')\n",
    "    discriminator = torch.load(args.checkpoint + '_discr')\n",
    "    opt_D = optim.Adam(discriminator.parameters(), lr = args.lr) # lr \n",
    "    opt_non_D = optim.Adam(list(encoder.parameters()) + list(predictor.parameters()), lr = args.lr) # lr \n",
    "    lr_scheduler_D = lr_scheduler.ExponentialLR(optimizer=opt_D, gamma=0.5 ** (1/(args.gamma_exp*(train_discr_step_extra+1)) * slow_lrD_decay))\n",
    "    lr_scheduler_non_D = lr_scheduler.ExponentialLR(optimizer=opt_non_D, gamma=0.5 ** (1/args.gamma_exp))\n",
    "    models = [encoder, predictor, discriminator]\n",
    "    for model in models:\n",
    "        for key, module in model._modules.items():\n",
    "            print('key', key)\n",
    "            print('module', module)\n",
    "\n",
    "if not args.evaluate:\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(epoch)\n",
    "        if epoch % 1 == 0:\n",
    "            test()\n",
    "cm=True\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
